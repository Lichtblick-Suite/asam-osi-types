// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.2.0
//   protoc               unknown
// source: osi_sensorviewconfiguration.proto

/* eslint-disable */
import {
  type Identifier,
  type MountingPosition,
  type Timestamp,
  type Vector3d,
  type WavelengthData,
} from "./osi_common";
import { type InterfaceVersion } from "./osi_version";

/**
 * \brief The configuration settings for the \c SensorView to be provided
 * by the environment simulation.
 *
 * This message can be provided by the sensor model to the environment
 * simulation, in which case it describes the input configuration that
 * is desired by the sensor model. In response the environment simulation
 * will configure the input and provide a new message of this type, which
 * describes the actual configuration that it is going to employ. The two
 * can and will differ, when either the environment simulation does not
 * support a given requested configuration, and/or when the requested
 * configuration allowed for multiple alternatives, in which case the set
 * configuration will only contain the alternative chosen.
 *
 * It should be noted that this message is not intended to provide for
 * parametrization of a generic sensor model, but rather for the automatic
 * configuration of an environment simulation in order to supply the
 * necessary input to it, depending on its actual configuration.
 * Mechanisms to parametrize sensor models are currently packaging-specific,
 * i.e. they depend on the packaging mechanism chosen:  For FMU-packaging
 * the parametrization can be implemented using normal FMU parameters,
 * and the requested \c SensorViewConfiguration can depend on those parameter
 * values by being defined as a calculatedParameter.
 *
 * The sensor-technology specific configurations are intended to allow
 * sensor models to use useful sensor modeling base capabilities of the
 * environment simulation (e.g. ray tracing engines, camera/lens image
 * generation), which need configuration by the sensor model to supply
 * suitable data. The specified details are not directly related to
 * sensor details, but rather provide the necessary base machinery
 * setup so that the data provided is suitable to model the sensor to
 * a sufficient degree of fidelity internally. For example the number
 * of rays parameters for the Lidar configuration does not match one to
 * one with the number of laser rays a lidar sensor might cast, but
 * rather specifies the number of rays being cast by a ray
 * casting/tracing engine, which might be many more than the physical
 * rays being cast at any point in time.
 *
 * This also implies that for sensors that have dynamically varying
 * characteristics (e.g. switching between wide and narrow focus,
 * switching update rates, etc.), the basic approach is to specify
 * the maximum amount of data needed at all times here, and internally
 * select the data that is needed at any point in time.
 *
 * In order to optimize the workload and bandwidth needed for sensor
 * simulation, OSI packaging mechanisms can specify the ability to
 * exchange \c SensorViewConfiguration messages not only prior to
 * simulation startup, but also dynamically during simulation runs,
 * thereby allowing dynamic input configuration switching to only
 * request data that is needed in the current sensor mode. However
 * this is more or less only a resource optimization strategy, and
 * since providing fine-grained information like this can reveal
 * internal characteristics of the sensor and/or sensor model, will
 * not always be the preferred approach for reasons of IP protection.
 */
export interface SensorViewConfiguration {
  /**
   * The interface version used by the sender (simulation environment).
   *
   * \rules
   * is_set
   * \endrules
   */
  version?:
    | InterfaceVersion
    | undefined;
  /**
   * The ID of the sensor at host vehicle's mounting_position.
   *
   * This is the ID of the virtual sensor, to be used in its detected
   * object output; it is distinct from the IDs of its physical detectors,
   * which are used in the detected features.
   *
   * The ID is to be provided by the environment simulation, the sensor
   * model is not in a position to provide a useful default value.
   *
   * \rules
   * is_set
   * \endrules
   */
  sensor_id?:
    | Identifier
    | undefined;
  /**
   * The virtual mounting position of the sensor (origin and orientation
   * of the sensor coordinate system) given in vehicle coordinates [1].
   * The virtual position pertains to the sensor as a whole, regardless
   * of the actual position of individual physical detectors, and governs
   * the sensor-relative coordinates in detected objects of the sensor
   * as a whole. Individual features detected by individual physical
   * detectors are governed by the actual physical mounting positions
   * of the detectors, as indicated in the technology-specific sub-views
   * and sub-view configurations.
   *
   * \arg \b x-direction of sensor coordinate system: sensor viewing direction
   * \arg \b z-direction of sensor coordinate system: sensor (up)
   * \arg \b y-direction of sensor coordinate system: perpendicular to x and z
   * right hand system
   *
   * \par Reference:
   * [1] DIN Deutsches Institut fuer Normung e. V. (2013). <em>DIN ISO 8855 Strassenfahrzeuge - Fahrzeugdynamik und Fahrverhalten - Begriffe</em>. (DIN ISO 8855:2013-11). Berlin, Germany.
   *
   * \note The origin of vehicle's coordinate system in world frame is
   * ( \c MovingObject::base . \c BaseMoving::position +
   * Inverse_Rotation_yaw_pitch_roll( \c MovingObject::base . \c
   * BaseMoving::orientation) * \c
   * MovingObject::VehicleAttributes::bbcenter_to_rear) . The orientation of
   * the vehicle's coordinate system is equal to the orientation of the
   * vehicle's bounding box \c MovingObject::base . \c
   * BaseMoving::orientation. \note A default position can be provided by the
   * sensor model (e.g. to indicate the position the model was validated for),
   * but this is optional; the environment simulation must provide a valid
   * mounting position (based on the vehicle configuration) when setting the
   * view configuration.
   */
  mounting_position?:
    | MountingPosition
    | undefined;
  /** The root mean squared error of the mounting position. */
  mounting_position_rmse?:
    | MountingPosition
    | undefined;
  /**
   * Field of View in horizontal orientation of the sensor.
   *
   * This determines the limit of the cone of interest of ground truth
   * that the simulation environment has to provide.
   * Viewing range: [- \c #field_of_view_horizontal/2,  \c
   * #field_of_view_horizontal/2] azimuth in the sensor frame as defined in \c
   * Spherical3d.
   *
   * Unit: rad
   */
  field_of_view_horizontal?:
    | number
    | undefined;
  /**
   * Field of View in vertical orientation of the sensor.
   *
   * This determines the limit of the cone of interest of ground truth
   * that the simulation environment has to provide.
   * Viewing range: [- \c #field_of_view_vertical/2,  \c
   * #field_of_view_vertical/2] elevation in the sensor frame at zero azimuth
   * as defined in \c Spherical3d.
   *
   * Unit: rad
   */
  field_of_view_vertical?:
    | number
    | undefined;
  /**
   * Maximum range of the sensor
   *
   * This determines the limit of the cone of interest of ground truth
   * that the simulation environment has to provide.
   *
   * Unit: m
   *
   * \rules
   * is_greater_than_or_equal_to: 0
   * \endrules
   */
  range?:
    | number
    | undefined;
  /**
   * The update cycle time of the sensor model.
   *
   * This specifies the rate at which the sensor model is provided with
   * new input data.
   *
   * Unit: s
   * \note In the case of FMU packaging this will correspond to the
   * communication step size.
   */
  update_cycle_time?:
    | Timestamp
    | undefined;
  /**
   * Initial update cycle offset of the sensor model.
   *
   * This specifies the initial offset (i.e. initial delay) of the
   * sensor model update cycle that the simulation should take into
   * account. It is defined against a simulation start time of 0:
   * i.e. an initial offset of 0.008s would mean, that the initial
   * update of sensor input data to the model should occur at 0+0.008s,
   * and then update_cycle_time after that, etc. If the simulation
   * start time of the simulation is non-zero, then the offset still
   * has to be interpreted against a 0 start time, and not simply
   * added on top of the start time: e.g. if the simulation starts at
   * 0.030s, and the update cycle time is 0.020s, then the first
   * update to the sensor input should happen at 0.048s, or 0.018s
   * after simulation start. This convention is needed to ensure
   * stable phase position of the offset in the case of changing
   * simulation start times, e.g. for partial re-simulation.
   *
   * Unit: s
   */
  update_cycle_offset?:
    | Timestamp
    | undefined;
  /**
   * Simulation Start time
   *
   * This specifies the simulation start time that the Simulation
   * has chosen. This field has no defined meaning if provided by
   * the sensor model.
   *
   * Unit: s
   */
  simulation_start_time?:
    | Timestamp
    | undefined;
  /**
   * Omit Static Information
   *
   * This flag specifies whether \c GroundTruth information that
   * was already provided using a GroundTruthInit parameter (e.g. <a href="https://opensimulationinterface.github.io/osi-antora-generator/asamosi/latest/sensor-model/spec/ground_truth_init_parameters.html">OSMP GroundTruthInit</a>)
   * at initialization time shall be omitted from the \c SensorView
   * ground truth information.
   *
   * Setting the \c #omit_static_information field allows a clear split
   * between the dynamic simulation data, which is contained in ground truth
   * messages with the \c #omit_static_information flag, and the static
   * simulation data, which is contained in the (OSMP) GroundTruthInit.
   */
  omit_static_information?:
    | boolean
    | undefined;
  /** Generic Sensor View Configuration(s). */
  generic_sensor_view_configuration?:
    | GenericSensorViewConfiguration[]
    | undefined;
  /** Radar-specific Sensor View Configuration(s). */
  radar_sensor_view_configuration?:
    | RadarSensorViewConfiguration[]
    | undefined;
  /** Lidar-specific Sensor View Configuration(s). */
  lidar_sensor_view_configuration?:
    | LidarSensorViewConfiguration[]
    | undefined;
  /** Camera-specific Sensor View Configuration(s). */
  camera_sensor_view_configuration?:
    | CameraSensorViewConfiguration[]
    | undefined;
  /** Ultrasonic-specific Sensor View Configuration(s). */
  ultrasonic_sensor_view_configuration?: UltrasonicSensorViewConfiguration[] | undefined;
}

/**
 * \brief The configuration settings for the Generic Sensor View to be provided
 * by the environment simulation.
 */
export interface GenericSensorViewConfiguration {
  /**
   * The ID of the sensor at host vehicle's mounting_position.
   *
   * This is the ID of the physical sensor, to be used in its detected
   * features output; it is distinct from the ID of its virtual sensor.
   *
   * The ID is to be provided by the environment simulation, the sensor
   * model is not in a position to provide a useful default value.
   */
  sensor_id?:
    | Identifier
    | undefined;
  /**
   * The physical mounting position of the sensor (origin and orientation
   * of the sensor coordinate system) given in vehicle coordinates [1].
   * The physical position pertains to this detector individually, and
   * governs the sensor-relative coordinates in features detected by this
   * detector.
   *
   * \arg \b x-direction of sensor coordinate system: sensor viewing direction
   * \arg \b z-direction of sensor coordinate system: sensor (up)
   * \arg \b y-direction of sensor coordinate system: perpendicular to x and z
   * right hand system
   *
   * \par Reference:
   * [1] DIN Deutsches Institut fuer Normung e. V. (2013). <em>DIN ISO 8855 Strassenfahrzeuge - Fahrzeugdynamik und Fahrverhalten - Begriffe</em>. (DIN ISO 8855:2013-11). Berlin, Germany.
   *
   * \note The origin of vehicle's coordinate system in world frame is
   * ( \c MovingObject::base . \c BaseMoving::position +
   * Inverse_Rotation_yaw_pitch_roll( \c MovingObject::base . \c
   * BaseMoving::orientation) * \c
   * MovingObject::VehicleAttributes::bbcenter_to_rear) . The orientation of
   * the vehicle's coordinate system is equal to the orientation of the
   * vehicle's bounding box \c MovingObject::base . \c
   * BaseMoving::orientation. \note A default position can be provided by the
   * sensor model (e.g. to indicate the position the model was validated for),
   * but this is optional; the environment simulation must provide a valid
   * mounting position (based on the vehicle configuration) when setting the
   * view configuration.
   */
  mounting_position?:
    | MountingPosition
    | undefined;
  /** The root mean squared error of the mounting position. */
  mounting_position_rmse?:
    | MountingPosition
    | undefined;
  /**
   * Field of View in horizontal orientation of the physical sensor.
   *
   * Viewing range: [- \c #field_of_view_horizontal/2,  \c
   * #field_of_view_horizontal/2] azimuth in the sensor frame as defined in \c
   * Spherical3d.
   *
   * Unit: rad
   */
  field_of_view_horizontal?:
    | number
    | undefined;
  /**
   * Field of View in vertical orientation of the physical sensor.
   *
   * Viewing range: [- \c #field_of_view_vertical/2,  \c
   * #field_of_view_vertical/2] elevation in the sensor frame at zero azimuth
   * as defined in \c Spherical3d.
   *
   * Unit: rad
   */
  field_of_view_vertical?: number | undefined;
}

/**
 * \brief The configuration settings for the Radar Sensor View to be provided
 * by the environment simulation.
 */
export interface RadarSensorViewConfiguration {
  /**
   * The ID of the sensor at host vehicle's mounting_position.
   *
   * This is the ID of the physical sensor, to be used in its detected
   * features output; it is distinct from the ID of its virtual sensor.
   *
   * The ID is to be provided by the environment simulation, the sensor
   * model is not in a position to provide a useful default value.
   */
  sensor_id?:
    | Identifier
    | undefined;
  /**
   * The physical mounting position of the sensor (origin and orientation
   * of the sensor coordinate system) given in vehicle coordinates [1].
   * The physical position pertains to this detector individually, and
   * governs the sensor-relative coordinates in features detected by this
   * detector.
   *
   * \arg \b x-direction of sensor coordinate system: sensor viewing direction
   * \arg \b z-direction of sensor coordinate system: sensor (up)
   * \arg \b y-direction of sensor coordinate system: perpendicular to x and z
   * right hand system
   *
   * \par Reference:
   * [1] DIN Deutsches Institut fuer Normung e. V. (2013). <em>DIN ISO 8855 Strassenfahrzeuge - Fahrzeugdynamik und Fahrverhalten - Begriffe</em>. (DIN ISO 8855:2013-11). Berlin, Germany.
   *
   * \note The origin of vehicle's coordinate system in world frame is
   * ( \c MovingObject::base . \c BaseMoving::position +
   * Inverse_Rotation_yaw_pitch_roll( \c MovingObject::base . \c
   * BaseMoving::orientation) * \c
   * MovingObject::VehicleAttributes::bbcenter_to_rear) . The orientation of
   * the vehicle's coordinate system is equal to the orientation of the
   * vehicle's bounding box \c MovingObject::base . \c
   * BaseMoving::orientation. \note A default position can be provided by the
   * sensor model (e.g. to indicate the position the model was validated for),
   * but this is optional; the environment simulation must provide a valid
   * mounting position (based on the vehicle configuration) when setting the
   * view configuration.
   */
  mounting_position?:
    | MountingPosition
    | undefined;
  /** The root mean squared error of the mounting position. */
  mounting_position_rmse?:
    | MountingPosition
    | undefined;
  /**
   * Field of View in horizontal orientation of the physical sensor.
   *
   * Viewing range: [- \c #field_of_view_horizontal/2,  \c
   * #field_of_view_horizontal/2] azimuth in the sensor frame as defined in \c
   * Spherical3d.
   *
   * Unit: rad
   */
  field_of_view_horizontal?:
    | number
    | undefined;
  /**
   * Field of View in vertical orientation of the physical sensor.
   *
   * Viewing range: [- \c #field_of_view_vertical/2,  \c
   * #field_of_view_vertical/2] elevation in the sensor frame at zero azimuth
   * as defined in \c Spherical3d.
   *
   * Unit: rad
   */
  field_of_view_vertical?:
    | number
    | undefined;
  /**
   * Number of rays to cast across horizontal field of view (azimuth).
   *
   * \note This is a characteristic of the ray tracing engine of the
   * environment simulation, not a direct characteristic of the sensor.
   *
   * \rules
   * is_greater_than_or_equal_to: 1
   * \endrules
   */
  number_of_rays_horizontal?:
    | number
    | undefined;
  /**
   * Number of rays to cast across vertical field of view (elevation).
   *
   * \note This is a characteristic of the ray tracing engine of the
   * environment simulation, not a direct characteristic of the sensor.
   *
   * \rules
   * is_greater_than_or_equal_to: 1
   * \endrules
   */
  number_of_rays_vertical?:
    | number
    | undefined;
  /**
   * Maximum number of interactions to take into account.
   *
   * \note This is a characteristic of the ray tracing engine of the
   * environment simulation, not a direct characteristic of the sensor.
   *
   * \rules
   * is_greater_than_or_equal_to: 1
   * \endrules
   */
  max_number_of_interactions?:
    | number
    | undefined;
  /**
   * Emitter Frequency.
   *
   * This information can be used by a ray tracing engine to calculate
   * doppler shift information and take into account differences in
   * refraction and reflection. For doppler shift calculations the
   * sensor model can of course always provide a nominal frequency and
   * adjust the resulting doppler shift information to actual frequency
   * through frequency adjustments. For material and geometry interaction
   * purposes the frequency is also relevant.
   *
   * Unit: Hz
   *
   * \rules
   * is_greater_than_or_equal_to: 0
   * \endrules
   */
  emitter_frequency?:
    | number
    | undefined;
  /** This represents the TX antenna diagram */
  tx_antenna_diagram?:
    | RadarSensorViewConfiguration_AntennaDiagramEntry[]
    | undefined;
  /** This represents the RX antenna diagram */
  rx_antenna_diagram?: RadarSensorViewConfiguration_AntennaDiagramEntry[] | undefined;
}

/**
 * \brief The radar antenna diagram.
 *
 * \note Rotation is defined analog Spherical3d
 */
export interface RadarSensorViewConfiguration_AntennaDiagramEntry {
  /**
   * Horizontal deflection (azimuth) of entry in sensor/antenna
   * coordinates.
   *
   * Unit: rad
   */
  horizontal_angle?:
    | number
    | undefined;
  /**
   * Vertical deflection (elevation) of entry in sensor/antenna
   * coordinates.
   *
   * Unit: rad
   */
  vertical_angle?:
    | number
    | undefined;
  /**
   * Response of antenna at this point (positive dB is gain,
   * negative dB is attenuation).
   *
   * Unit: dB
   */
  response?: number | undefined;
}

/**
 * \brief The configuration settings for the Lidar Sensor View to be provided
 * by the environment simulation.
 */
export interface LidarSensorViewConfiguration {
  /**
   * The ID of the sensor at host vehicle's mounting_position.
   *
   * This is the ID of the physical sensor, to be used in its detected
   * features output; it is distinct from the ID of its virtual sensor.
   *
   * The ID is to be provided by the environment simulation, the sensor
   * model is not in a position to provide a useful default value.
   */
  sensor_id?:
    | Identifier
    | undefined;
  /**
   * The physical mounting position of the sensor (origin and orientation
   * of the sensor coordinate system) given in vehicle coordinates [1].
   * The physical position pertains to this detector individually, and
   * governs the sensor-relative coordinates in features detected by this
   * detector.
   *
   * \arg \b x-direction of sensor coordinate system: sensor viewing direction
   * \arg \b z-direction of sensor coordinate system: sensor (up)
   * \arg \b y-direction of sensor coordinate system: perpendicular to x and z
   * right hand system
   *
   * \par Reference:
   * [1] DIN Deutsches Institut fuer Normung e. V. (2013). <em>DIN ISO 8855 Strassenfahrzeuge - Fahrzeugdynamik und Fahrverhalten - Begriffe</em>. (DIN ISO 8855:2013-11). Berlin, Germany.
   *
   * \note The origin of vehicle's coordinate system in world frame is
   * ( \c MovingObject::base . \c BaseMoving::position +
   * Inverse_Rotation_yaw_pitch_roll( \c MovingObject::base . \c
   * BaseMoving::orientation) * \c
   * MovingObject::VehicleAttributes::bbcenter_to_rear) . The orientation of
   * the vehicle's coordinate system is equal to the orientation of the
   * vehicle's bounding box \c MovingObject::base . \c
   * BaseMoving::orientation. \note A default position can be provided by the
   * sensor model (e.g. to indicate the position the model was validated for),
   * but this is optional; the environment simulation must provide a valid
   * mounting position (based on the vehicle configuration) when setting the
   * view configuration.
   */
  mounting_position?:
    | MountingPosition
    | undefined;
  /** The root mean squared error of the mounting position. */
  mounting_position_rmse?:
    | MountingPosition
    | undefined;
  /**
   * Field of View in horizontal orientation of the physical sensor.
   *
   * Viewing range: [- \c #field_of_view_horizontal/2,  \c
   * #field_of_view_horizontal/2] azimuth in the sensor frame as defined in \c
   * Spherical3d.
   *
   * Unit: rad
   */
  field_of_view_horizontal?:
    | number
    | undefined;
  /**
   * Field of View in vertical orientation of the physical sensor.
   *
   * Viewing range: [- \c #field_of_view_vertical/2,  \c
   * #field_of_view_vertical/2] elevation in the sensor frame at zero azimuth
   * as defined in \c Spherical3d.
   *
   * Unit: rad
   */
  field_of_view_vertical?:
    | number
    | undefined;
  /**
   * Number of rays to cast across horizontal field of view.
   *
   * \note This is a characteristic of the ray tracing engine of the
   * environment simulation, not a direct characteristic of the sensor.
   *
   * \rules
   * is_greater_than_or_equal_to: 1
   * \endrules
   */
  number_of_rays_horizontal?:
    | number
    | undefined;
  /**
   * Number of rays to cast across vertical field of view.
   *
   * \note This is a characteristic of the ray tracing engine of the
   * environment simulation, not a direct characteristic of the sensor.
   *
   * \rules
   * is_greater_than_or_equal_to: 1
   * \endrules
   */
  number_of_rays_vertical?:
    | number
    | undefined;
  /**
   * Maximum number of interactions to take into account.
   *
   * \note This is a characteristic of the ray tracing engine of the
   * environment simulation, not a direct characteristic of the sensor.
   *
   * \rules
   * is_greater_than_or_equal_to: 1
   * \endrules
   */
  max_number_of_interactions?:
    | number
    | undefined;
  /**
   * Emitter Frequency.
   *
   * This information can be used by a ray tracing engine to calculate
   * doppler shift information and take into account differences in
   * refraction and reflection. For doppler shift calculations the
   * sensor model can of course always provide a nominal frequency and
   * adjust the resulting doppler shift information to actual frequency
   * through frequency adjustments. For material and geometry interaction
   * purposes the frequency is also relevant.
   *
   * Unit: Hz
   *
   * \rules
   * is_greater_than_or_equal_to: 0
   * \endrules
   */
  emitter_frequency?:
    | number
    | undefined;
  /**
   * Number of pixels in frame.
   *
   * This field includes the number of pixels in each frame
   *
   * \rules
   * is_greater_than_or_equal_to: 1
   * \endrules
   */
  num_of_pixels?:
    | number
    | undefined;
  /**
   * Ray tracing data.
   *
   * The directions unit vectors describing the Lidar's raster transmission
   * directions. Length is num_of_pixels \note data is in Lidar's coordinate
   * system
   */
  directions?:
    | Vector3d[]
    | undefined;
  /**
   * Ray tracing data.
   *
   * The time offset in microseconds of every measurement from each frame
   * timestamp. Length is num_of_pixels
   */
  timings?: number[] | undefined;
}

/**
 * \brief The configuration settings for the Camera Sensor View to be provided
 * by the environment simulation.
 */
export interface CameraSensorViewConfiguration {
  /**
   * The ID of the sensor at host vehicle's mounting_position.
   *
   * This is the ID of the physical sensor, to be used in its detected
   * features output; it is distinct from the ID of its virtual sensor.
   *
   * The ID is to be provided by the environment simulation, the sensor
   * model is not in a position to provide a useful default value.
   */
  sensor_id?:
    | Identifier
    | undefined;
  /**
   * The physical mounting position of the sensor (origin and orientation
   * of the sensor coordinate system) given in vehicle coordinates [1].
   * The physical position pertains to this detector individually, and
   * governs the sensor-relative coordinates in features detected by this
   * detector.
   *
   * \arg \b x-direction of sensor coordinate system: sensor viewing direction
   * \arg \b z-direction of sensor coordinate system: sensor (up)
   * \arg \b y-direction of sensor coordinate system: perpendicular to x and z
   * right hand system
   *
   * \par Reference:
   * [1] DIN Deutsches Institut fuer Normung e. V. (2013). <em>DIN ISO 8855 Strassenfahrzeuge - Fahrzeugdynamik und Fahrverhalten - Begriffe</em>. (DIN ISO 8855:2013-11). Berlin, Germany.
   *
   * \note The origin of vehicle's coordinate system in world frame is
   * ( \c MovingObject::base . \c BaseMoving::position +
   * Inverse_Rotation_yaw_pitch_roll( \c MovingObject::base . \c
   * BaseMoving::orientation) * \c
   * MovingObject::VehicleAttributes::bbcenter_to_rear) . The orientation of
   * the vehicle's coordinate system is equal to the orientation of the
   * vehicle's bounding box \c MovingObject::base . \c
   * BaseMoving::orientation. \note A default position can be provided by the
   * sensor model (e.g. to indicate the position the model was validated for),
   * but this is optional; the environment simulation must provide a valid
   * mounting position (based on the vehicle configuration) when setting the
   * view configuration.
   */
  mounting_position?:
    | MountingPosition
    | undefined;
  /** The root mean squared error of the mounting position. */
  mounting_position_rmse?:
    | MountingPosition
    | undefined;
  /**
   * Field of View in horizontal orientation of the physical sensor.
   *
   * Viewing range: [- \c #field_of_view_horizontal/2,  \c
   * #field_of_view_horizontal/2] azimuth in the sensor frame as defined in \c
   * Spherical3d.
   *
   * Unit: rad
   */
  field_of_view_horizontal?:
    | number
    | undefined;
  /**
   * Field of View in vertical orientation of the physical sensor.
   *
   * Viewing range: [- \c #field_of_view_vertical/2,  \c
   * #field_of_view_vertical/2] elevation in the sensor frame at zero azimuth
   * as defined in \c Spherical3d.
   *
   * Unit: rad
   */
  field_of_view_vertical?:
    | number
    | undefined;
  /**
   * Number of pixels to produce across horizontal field of view.
   *
   * \note This is a characteristic of the rendering engine of the
   * environment simulation, not a direct characteristic of the sensor.
   *
   * \rules
   * is_greater_than_or_equal_to: 1
   * \endrules
   */
  number_of_pixels_horizontal?:
    | number
    | undefined;
  /**
   * Number of pixels to produce across horizontal field of view.
   *
   * \note This is a characteristic of the rendering engine of the
   * environment simulation, not a direct characteristic of the sensor.
   *
   * \rules
   * is_greater_than_or_equal_to: 1
   * \endrules
   */
  number_of_pixels_vertical?:
    | number
    | undefined;
  /**
   * Format for image data (includes number, kind and format of channels).
   *
   * In the message provided by the sensor model, this field can
   * be repeated and all values are acceptable to the model, with
   * the most acceptable value being listed first, and the remaining
   * values indicating alternatives in descending order of preference.
   *
   * In the message provided to the sensor model, this field must
   * contain exactly one value, indicating the format of the image
   * data being provided by the simulation environment - which must
   * be one of the values the sensor model requested - or there
   * must be no value, indicating that the simulation environment
   * cannot provide image data in one of the requested formats.
   *
   * \rules
   * is_greater_than_or_equal_to: 1
   * \endrules
   */
  channel_format?:
    | CameraSensorViewConfiguration_ChannelFormat[]
    | undefined;
  /**
   * Number of samples per pixel.
   *
   * \note This is a characteristic of the ray tracing engine of the
   * environment simulation, not a direct characteristic of the sensor.
   *
   * \rules
   * is_greater_than_or_equal_to: 1
   * \endrules
   */
  samples_per_pixel?:
    | number
    | undefined;
  /**
   * Maximum number of interactions to take into account.
   *
   * \note This is a characteristic of the ray tracing engine of the
   * environment simulation, not a direct characteristic of the sensor.
   *
   * \rules
   * is_greater_than_or_equal_to: 1
   * \endrules
   */
  max_number_of_interactions?:
    | number
    | undefined;
  /**
   * In use-cases where a spectral ray-tracer is used, this message
   * determines the range of the wavelength and its desired number
   * of samples.
   */
  wavelength_data?:
    | WavelengthData[]
    | undefined;
  /**
   * Indicates if and how the the pixel data is ordered
   *
   * The default value (PIXEL_ORDER_DEFAULT) indicates standard image
   * pixel order (left-to-right, top-to-bottom). The other values can
   * be used to indicate/request mirroring (right to left or bottom to top).
   *
   * \note For rotations of the pixel data, use the camera coordinate system.
   */
  pixel_order?: CameraSensorViewConfiguration_PixelOrder | undefined;
}

/**
 * Pixel layout
 *
 * Pixel layout documents the order of pixels in the \c image_data
 * in CameraSensorView.
 *
 * \note this enum does not contain an entry to do mirroring upside down
 * and left-to-right at the same time, because this is equivalent to a
 * 180-degree rotation, which should be indicated in the sensor coordinate
 * system.
 */
export enum CameraSensorViewConfiguration_PixelOrder {
  /**
   * DEFAULT - Pixel data is not mirrored (Default).
   * Pixels are ordered left-to-right, top-to-bottom.
   */
  DEFAULT = 0,
  /**
   * OTHER - Known pixel order that is not supported by OSI.
   * Consider proposing an additional format if using
   * \c #PIXEL_ORDER_OTHER.
   */
  OTHER = 1,
  /**
   * RIGHT_LEFT_TOP_BOTTOM - Pixels are ordered right-to-left, top-to-bottom.
   * Pixel data is mirrored along the vertical axis.
   * The image is mirrored left-to-right.
   */
  RIGHT_LEFT_TOP_BOTTOM = 2,
  /**
   * LEFT_RIGHT_BOTTOM_TOP - Pixels are ordered left-to-right, bottom-to-top.
   * Pixel data is mirrored along the horizontal axis.
   * The image is mirrored top-to-bottom.
   */
  LEFT_RIGHT_BOTTOM_TOP = 3,
}

/** Channel format. */
export enum CameraSensorViewConfiguration_ChannelFormat {
  /** UNKNOWN - Type of channel format is unknown (must not be used). */
  UNKNOWN = 0,
  /**
   * OTHER - Unspecified but known channel format.
   * Consider proposing an additional format if using
   * \c #CHANNEL_FORMAT_OTHER.
   */
  OTHER = 1,
  /** MONO_U8_LIN - Single Luminance Channel UINT8 Linear. */
  MONO_U8_LIN = 2,
  /** MONO_U16_LIN - Single Luminance Channel UINT16 Linear. */
  MONO_U16_LIN = 3,
  /** MONO_U32_LIN - Single Luminance Channel UINT32 Linear. */
  MONO_U32_LIN = 4,
  /** MONO_F32_LIN - Single Luminance Channel Single Precision FP Linear. */
  MONO_F32_LIN = 5,
  /** RGB_U8_LIN - Packed RGB Channels (no padding) UINT8 Linear. */
  RGB_U8_LIN = 6,
  /** RGB_U16_LIN - Packed RGB Channels (no padding) UINT16 Linear. */
  RGB_U16_LIN = 7,
  /** RGB_U32_LIN - Packed RGB Channels (no padding) UINT32 Linear. */
  RGB_U32_LIN = 8,
  /** RGB_F32_LIN - Packed RGB Channels (no padding) Single Precision FP Linear. */
  RGB_F32_LIN = 9,
  /** BAYER_BGGR_U8_LIN - Bayer BGGR Channels UINT8 FP Linear. */
  BAYER_BGGR_U8_LIN = 10,
  /** BAYER_BGGR_U16_LIN - Bayer BGGR Channels UINT16 FP Linear. */
  BAYER_BGGR_U16_LIN = 11,
  /** BAYER_BGGR_U32_LIN - Bayer BGGR Channels UINT32 FP Linear. */
  BAYER_BGGR_U32_LIN = 12,
  /** BAYER_BGGR_F32_LIN - Bayer BGGR Channels Single Precision FP Linear. */
  BAYER_BGGR_F32_LIN = 13,
  /** BAYER_RGGB_U8_LIN - Bayer RGGB Channels UINT8 FP Linear. */
  BAYER_RGGB_U8_LIN = 14,
  /** BAYER_RGGB_U16_LIN - Bayer RGGB Channels UINT16 FP Linear. */
  BAYER_RGGB_U16_LIN = 15,
  /** BAYER_RGGB_U32_LIN - Bayer RGGB Channels UINT32 FP Linear. */
  BAYER_RGGB_U32_LIN = 16,
  /** BAYER_RGGB_F32_LIN - Bayer RGGB Channels Single Precision FP Linear. */
  BAYER_RGGB_F32_LIN = 17,
  /** RCCC_U8_LIN - Red Clear Clear Clear Channels UINT8 FP Linear. */
  RCCC_U8_LIN = 18,
  /** RCCC_U16_LIN - Red Clear Clear Clear Channels UINT16 FP Linear. */
  RCCC_U16_LIN = 19,
  /** RCCC_U32_LIN - Red Clear Clear Clear Channels UINT32 FP Linear. */
  RCCC_U32_LIN = 20,
  /** RCCC_F32_LIN - Red Clear Clear Clear Channels Single Precision FP Linear. */
  RCCC_F32_LIN = 21,
  /** RCCB_U8_LIN - Red Clear Clear Blue Channels UINT8 FP Linear. */
  RCCB_U8_LIN = 22,
  /** RCCB_U16_LIN - Red Clear Clear Blue Channels UINT16 FP Linear. */
  RCCB_U16_LIN = 23,
  /** RCCB_U32_LIN - Red Clear Clear Blue Channels UINT32 FP Linear. */
  RCCB_U32_LIN = 24,
  /** RCCB_F32_LIN - Red Clear Clear Blue Channels Single Precision FP Linear. */
  RCCB_F32_LIN = 25,
}

/**
 * \brief The configuration settings for the Ultrasonic Sensor View to be
 * provided by the environment simulation.
 */
export interface UltrasonicSensorViewConfiguration {
  /**
   * The ID of the sensor at host vehicle's mounting_position.
   *
   * This is the ID of the physical sensor, to be used in its detected
   * features output; it is distinct from the ID of its virtual sensor.
   *
   * The ID is to be provided by the environment simulation, the sensor
   * model is not in a position to provide a useful default value.
   */
  sensor_id?:
    | Identifier
    | undefined;
  /**
   * The physical mounting position of the sensor (origin and orientation
   * of the sensor coordinate system) given in vehicle coordinates [1].
   * The physical position pertains to this detector individually, and
   * governs the sensor-relative coordinates in features detected by this
   * detector.
   *
   * \arg \b x-direction of sensor coordinate system: sensor viewing direction
   * \arg \b z-direction of sensor coordinate system: sensor (up)
   * \arg \b y-direction of sensor coordinate system: perpendicular to x and z
   * right hand system
   *
   * \par Reference:
   * [1] DIN Deutsches Institut fuer Normung e. V. (2013). <em>DIN ISO 8855 Strassenfahrzeuge - Fahrzeugdynamik und Fahrverhalten - Begriffe</em>. (DIN ISO 8855:2013-11). Berlin, Germany.
   *
   * \note The origin of vehicle's coordinate system in world frame is
   * ( \c MovingObject::base . \c BaseMoving::position +
   * Inverse_Rotation_yaw_pitch_roll( \c MovingObject::base . \c
   * BaseMoving::orientation) * \c
   * MovingObject::VehicleAttributes::bbcenter_to_rear) . The orientation of
   * the vehicle's coordinate system is equal to the orientation of the
   * vehicle's bounding box \c MovingObject::base . \c
   * BaseMoving::orientation. \note A default position can be provided by the
   * sensor model (e.g. to indicate the position the model was validated for),
   * but this is optional; the environment simulation must provide a valid
   * mounting position (based on the vehicle configuration) when setting the
   * view configuration.
   */
  mounting_position?:
    | MountingPosition
    | undefined;
  /** The root mean squared error of the mounting position. */
  mounting_position_rmse?:
    | MountingPosition
    | undefined;
  /**
   * Field of View in horizontal orientation of the physical sensor.
   *
   * Viewing range: [- \c #field_of_view_horizontal/2,  \c
   * #field_of_view_horizontal/2] azimuth in the sensor frame as defined in \c
   * Spherical3d.
   *
   * Unit: rad
   */
  field_of_view_horizontal?:
    | number
    | undefined;
  /**
   * Field of View in vertical orientation of the physical sensor.
   *
   * Viewing range: [- \c #field_of_view_vertical/2,  \c
   * #field_of_view_vertical/2] elevation in the sensor frame at zero azimuth
   * as defined in \c Spherical3d.
   *
   * Unit: rad
   */
  field_of_view_vertical?: number | undefined;
}
